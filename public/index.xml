<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>About the Blog on Debaditya Tech Journal</title>
    <link>/</link>
    <description>Recent content in About the Blog on Debaditya Tech Journal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 16 Aug 2020 15:47:23 -0400</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Code Programming Post</title>
      <link>/code-programming-post/_index./</link>
      <pubDate>Fri, 14 Aug 2020 20:22:49 -0400</pubDate>
      
      <guid>/code-programming-post/_index./</guid>
      <description>Code Programming Post   Journey on Code and Programming</description>
    </item>
    
    <item>
      <title>Database Sharding</title>
      <link>/system-design-post/installation/</link>
      <pubDate>Sun, 16 Aug 2020 15:47:23 -0400</pubDate>
      
      <guid>/system-design-post/installation/</guid>
      <description>Simple definition Process of making paritions of data in database
Vertical and Horizontal Sharding Let us understand using simple example
Table   Veritical Sharding   Horizontal Sharding Sharding is performed on the basis of salary.
 Horizontal Shard1 = salary &amp;lt; 100000 Horizontal Shard2 = salary &amp;gt; 100000 AND salary &amp;lt; 250000 Horizontal Shard3 = salary &amp;gt; 250000    Benefits of Sharding  Improves the efficiency of queries Sharding results to small logical table which makes query faster Read and write performance increases  Problems with Sharding  Joining data across shards is expensive process as the join happens across the network Too many shards is a problem and increase the overhead  What happens the shard fails ?</description>
    </item>
    
    <item>
      <title>Windowing in Data Stream Management</title>
      <link>/system-design-post/windowops/</link>
      <pubDate>Sun, 16 Aug 2020 13:01:06 -0400</pubDate>
      
      <guid>/system-design-post/windowops/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spark Structured Streaming</title>
      <link>/code-programming-post/srucstream/</link>
      <pubDate>Fri, 14 Aug 2020 20:22:49 -0400</pubDate>
      
      <guid>/code-programming-post/srucstream/</guid>
      <description>Comparison of Spark streaming , Structured streaming and Kafka Streams   What is a Watermark? Its a method to hande the lateness. Basically , it can be regarded as threshold to specify how long system wait before data arrives. If the event falls under the watermark interval , then the event&amp;rsquo;s data is utilized for computation else the event&amp;rsquo;s data is dropped for that time interval.
Unsupported Operations in Structured Spark streaming  Multiple streaming aggregations are not yet supported on streaming Datasets.</description>
    </item>
    
    <item>
      <title>Machine Learning in AWS</title>
      <link>/ai-ml-post/awsml/</link>
      <pubDate>Sun, 09 Aug 2020 11:29:04 -0400</pubDate>
      
      <guid>/ai-ml-post/awsml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Basic code : Spark streaming</title>
      <link>/code-programming-post/sparkstream/</link>
      <pubDate>Sun, 09 Aug 2020 02:47:18 -0400</pubDate>
      
      <guid>/code-programming-post/sparkstream/</guid>
      <description>Spark Streaming DStreams (Discretized Streams)  It is an abstraction provided by Spark streaming It is basically represents series of RDD     Directory monitoring (dataDirectory) is described here
Window Operations Spark provides window operation which helps to perform transformation on sliding window    Window length - The duration of the window Sliding interval - The interval at which the window operation is performed  Example of window operation # Reduce last 30 seconds of data, every 10 seconds windowedWordCounts = pairs.</description>
    </item>
    
    <item>
      <title>Spark Commands</title>
      <link>/code-programming-post/sparkcommands/</link>
      <pubDate>Sat, 08 Aug 2020 20:57:34 -0400</pubDate>
      
      <guid>/code-programming-post/sparkcommands/</guid>
      <description>Useful Site Analytics Vidya link
Commands </description>
    </item>
    
    <item>
      <title>Brief on Spark Memory and Optimizer </title>
      <link>/code-programming-post/sparkmemory/</link>
      <pubDate>Sat, 08 Aug 2020 20:28:12 -0400</pubDate>
      
      <guid>/code-programming-post/sparkmemory/</guid>
      <description>Spark Memory and Optimizer Optimizer   Core of Spark SQL has Catalyst optimizer which leverages 2 important Scala features
 Pattern matching Quasi Notes (Easy to generate code at runtime from composable expressions)    Catalyst supports both rule-based and cost-based optimization.
  Designed for 2 main pruposes :
 Easily add new optimization techniques and features to Spark SQL Enable external developers to extend the optimizer (e.</description>
    </item>
    
    <item>
      <title>About Kafka</title>
      <link>/system-design-post/kafka/</link>
      <pubDate>Sat, 08 Aug 2020 18:04:27 -0400</pubDate>
      
      <guid>/system-design-post/kafka/</guid>
      <description>Kafka Architecture   Kafka uses ZooKeeper to manage the cluster.
  ZooKeeper is used to coordinate the brokers/cluster topology.
  ZooKeeper gets used for leadership election for Broker Topic Partition Leaders.
  Kafka producers write to Topics -&amp;gt; Kafka consumers read from Topics.
  Topic is associated with a log which is data structure on disk. Kafka appends records from a producer(s) to the end of a topic log.</description>
    </item>
    
    <item>
      <title>Spark definition and overall execution</title>
      <link>/code-programming-post/sparklearn/</link>
      <pubDate>Sat, 08 Aug 2020 17:14:45 -0400</pubDate>
      
      <guid>/code-programming-post/sparklearn/</guid>
      <description>Install Spark For Windows : Please follow this site
Basics of Spark Flow Run Spark application -&amp;gt; Driver program starts -&amp;gt; Main function starts -&amp;gt; SparkContext gets initiated -&amp;gt; Driver program runs the operations inside the executors on worker nodes. SparkContext uses Py4J to launch a JVM and creates a JavaSparkContext. By default, PySpark has SparkContext available as ‘sc’, so creating a new SparkContext won&amp;rsquo;t work.
Serialization and Deserialization Serialization is a mechanism of converting the state of an object into a byte stream.</description>
    </item>
    
    <item>
      <title>Nutshell on Synchronous and Asynchronous process</title>
      <link>/system-design-post/synasync/</link>
      <pubDate>Sat, 01 Aug 2020 23:36:51 -0400</pubDate>
      
      <guid>/system-design-post/synasync/</guid>
      <description>Real life examples   Synchronous processing : Getting movie ticket from counter , Phone call , video conferencing.
  Asynchronous processing : Ordering food in restaurant , FTP , email , social media.
  Synchronous and Asynchronous process  Synchronous processing : Synchronous execution means the execution happens in a single series.  Single Thread |&amp;lt;---T1----&amp;gt;||&amp;lt;----T2----------&amp;gt;||&amp;lt;------T3-----&amp;gt;| Multi Thread thread A -&amp;gt; |&amp;lt;---A----&amp;gt;| thread B ----------------&amp;gt;|&amp;lt;----B----------&amp;gt;| thread C -------------------------------------&amp;gt;|&amp;lt;------C-----&amp;gt;|  Asynchronous processing : Execution of a multiple process can happen without having dependency on each other.</description>
    </item>
    
    <item>
      <title>Event Driven model</title>
      <link>/system-design-post/evntdrive/</link>
      <pubDate>Sat, 01 Aug 2020 15:03:38 -0400</pubDate>
      
      <guid>/system-design-post/evntdrive/</guid>
      <description>Event Driven Model Event driven model is based on either Pub/sub or Event streaming model
Pub-sub model Messaging infrastructure is based on subscription based model (Active MQ)
Event streaming model Events are written into logs. Consumers need not require to subscribe event - rather they can be read or join from any part of the stream (Kafka)
System Design - Microservice + Kafka + KSQL Picture credits : Please visit Confluent site for more details</description>
    </item>
    
    <item>
      <title>All about Eventual and Strongly Consistency</title>
      <link>/system-design-post/evntconst/</link>
      <pubDate>Tue, 28 Jul 2020 23:15:05 -0400</pubDate>
      
      <guid>/system-design-post/evntconst/</guid>
      <description>Eventual Consistent  Mainly used in NoSQL databases (Solr, Cassandra , MongoDb) Used for analytics , time series analysis , etc Low latency - Faster writes    Please follow Werner Voggel&amp;rsquo;s blog - here
Strongly Consistent  Mainly used in RDBMS like Oracle , MySQL , PostgreSQL Primarily used in banking and payment systems High latency - Slower writes    Please read about F1 database by Google here Photo Credits : Google Blog</description>
    </item>
    
    <item>
      <title>Demystify Lambda and Kappa Architecture</title>
      <link>/system-design-post/lamkapp/</link>
      <pubDate>Mon, 27 Jul 2020 21:15:14 -0400</pubDate>
      
      <guid>/system-design-post/lamkapp/</guid>
      <description>Nutshell Lambda vs Kappa Architecture   Lambda Architecture   Kappa Architecture   Picture credits are to Talend.
Please visit Talend site here for more details.</description>
    </item>
    
    <item>
      <title>Vertical vs Horizontal Scaling</title>
      <link>/system-design-post/verticalhorizaonal/</link>
      <pubDate>Sun, 26 Jul 2020 16:30:42 -0400</pubDate>
      
      <guid>/system-design-post/verticalhorizaonal/</guid>
      <description>Nutshell  Horizontal scaling means that we scale by adding more machines into pool of resources Vertical scaling means that we scale by adding more power (CPU, RAM) to an existing machine.  High level difference   Real world implementation Take the benfits of both Horizontal and Vertical scaling
 Vertical scaling : Inter process communication and data consistency Horizontal scaling : Scalability and Resilient (no single point of failure)  Ideal way - First have the veritical scaling (optimal level) and scale horizontally.</description>
    </item>
    
    <item>
      <title>AWS Basic Terminologies</title>
      <link>/system-design-post/awsterminology/</link>
      <pubDate>Fri, 24 Jul 2020 00:10:26 -0400</pubDate>
      
      <guid>/system-design-post/awsterminology/</guid>
      <description>Terminology credits : intellipaat.com Networking Services  VPC: Amazon Virtual Private Cloud (VPC) is a virtual data center in AWS consisting of a set of isolated resources. Direct Connect: It is used to establish a dedicated network connection from the host network to AWS without an Internet connection. Route 53: It is a scalable and highly available Domain Name System (DNS) and domain name registration service, and 53 is the port on which this service runs.</description>
    </item>
    
    <item>
      <title>Time &amp; Space Complexity</title>
      <link>/code-programming-post/tscomplexity/</link>
      <pubDate>Fri, 24 Jul 2020 00:03:26 -0400</pubDate>
      
      <guid>/code-programming-post/tscomplexity/</guid>
      <description>Time Complexity Big-O , Big-Omega , Big-Theta
 Big-O is the upper asymptotic bound for an algorithm . Worst-case scenarios Big-Omega is the lower bound asymptotic bound of an algorithm. Bast-case sceanrio Big-Theta is in between lower and upper asymptotic bound (tight bound) of an algorithm. Average or expected case scenario  Space Complexity Amount of memory or space required by an algorithm
In recursive calls counts,the code would take 0 (n) time and O( n) space.</description>
    </item>
    
    <item>
      <title>What is Caching and its importance</title>
      <link>/system-design-post/caching/</link>
      <pubDate>Sun, 19 Jul 2020 22:20:15 -0400</pubDate>
      
      <guid>/system-design-post/caching/</guid>
      <description>3 Main use-case of Cache  Avoid Network calls Avoid repeated computation Avoid load on Database / System  Why not use cache every time  Hardware where Cache runs are mainly in SSDs which are expensive More data in Cache will increase the search time - so it will make cache data retrieval slower  Cache Policy The way we decide to load or evict data from cache is called Cache policy</description>
    </item>
    
    <item>
      <title>About Zookeeper</title>
      <link>/system-design-post/zookeeper/</link>
      <pubDate>Thu, 16 Jul 2020 21:19:21 -0400</pubDate>
      
      <guid>/system-design-post/zookeeper/</guid>
      <description>Definition Zookeeper is registry for large distributed systems. It is beneficial for tasks like master election, crash detection and managing meta data related to distributed systems.
The ZooKeeper framework was originally built at “Yahoo!” for accessing their applications in an easy and robust manner. Apache ZooKeeper is a standard for organized service used by Hadoop, HBase, and other distributed frameworks.
Services Provided by Zookeeper (NCCLLH - thats How I remember)   Naming service − Identifying the nodes in a cluster by name.</description>
    </item>
    
    <item>
      <title>Load Balancer</title>
      <link>/system-design-post/loadbalance/</link>
      <pubDate>Thu, 16 Jul 2020 20:54:54 -0400</pubDate>
      
      <guid>/system-design-post/loadbalance/</guid>
      <description>Definition Load Balancing is the process of re-distributing network traffic across multiple server.
  What Load Balancers can perform ?  Detect server failures and redirect client traffic automatically/ Provide automated disaster recovery to backup sites Add and remove application servers without disruption Monitor and block malicious content  Load Balance Algorithms (remember as CRRI) There is a variety of load balancing methods, which use different algorithms best suited for a particular situation.</description>
    </item>
    
    <item>
      <title>Demystifying HTTP and HTTPS</title>
      <link>/system-design-post/https/</link>
      <pubDate>Tue, 14 Jul 2020 09:58:29 -0400</pubDate>
      
      <guid>/system-design-post/https/</guid>
      <description>HTTP and HTTPS HTTPS (Hyper Text transfer protoco secure) is basically http with security. SSL (Secure Socket Layer) certificate encrypts information users put into any website. Addtionally, HTTPS is also secured via TLS (Transport Layer Security) protocol. TLS is a succcessotr of SSL.
SSL / TLS SSL/TLS works by binding the identities of entities such as websites and companies to cryptographic key pairs via digital documents known as X.509 certificates. Each key pair consists of a private key and a public key.</description>
    </item>
    
    <item>
      <title>What is REST &amp; SOAP</title>
      <link>/system-design-post/restsoap/</link>
      <pubDate>Mon, 13 Jul 2020 19:54:23 -0400</pubDate>
      
      <guid>/system-design-post/restsoap/</guid>
      <description>REST and SOAP are terms which are often used by engineers. But one must know that REST is architechtural style while SOAP is protocol.
REST vs SOAP   When to use REST &amp;amp; SOAP REST Usage  Limited resources and bandwidth Statelessness – Any Use-case which doesnot need to store the state. This means REST is not suitable for any online purchase site. Saving the state is very critical for any purchase site.</description>
    </item>
    
    <item>
      <title>Authentication vs Authorization</title>
      <link>/system-design-post/auth/</link>
      <pubDate>Sun, 12 Jul 2020 16:51:09 -0400</pubDate>
      
      <guid>/system-design-post/auth/</guid>
      <description>Definition Authentication and authorization are important terms in world of security. Often these 2 words are confused and can be used interchangeably. In this blog, a simple differentiation has been tried to lay out to clearly define both the terms in layman&amp;rsquo;s language.
  </description>
    </item>
    
    <item>
      <title>Word2Vec Algorithm</title>
      <link>/ai-ml-post/word2vec/</link>
      <pubDate>Sat, 11 Jul 2020 20:24:10 -0400</pubDate>
      
      <guid>/ai-ml-post/word2vec/</guid>
      <description>About Word2Vec algorithm  Word2Vec is not a single algorithm Word2vec is a group of related models that are used to produce word embedding&amp;rsquo;s. These models are two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes large corpus of text as its input and produces a vector-space, with each unique word in the corpus being assigned a corresponding vector in the space.  Word2Vec can utilize either of 2 model architectures –  CBOW (Continuous Bag of Words) Skip Gram    CBOW (Continuous Bag of Words) The input to the model could be wi−2,wi−1,wi+1,wi+2wi−2,wi−1,wi+1,wi+2, the preceding and following words of the current word we are at.</description>
    </item>
    
    <item>
      <title>OSI Model Layer</title>
      <link>/system-design-post/osilayer/</link>
      <pubDate>Sat, 11 Jul 2020 19:29:02 -0400</pubDate>
      
      <guid>/system-design-post/osilayer/</guid>
      <description>About OSI Model OSI stands for Open System Interconnection Model enables syetems to communicate using standard protocols. It is based on 7 layers . During my college days, I used to remeber it as &amp;ldquo;PDN-T-SPA&amp;rdquo; which is Physical , Data , Network , Transport , Session , Presentation and Application layer.
  Comparing OSI Model Layer with TCP/IP model   </description>
    </item>
    
    <item>
      <title>Trees in Machine Learning World</title>
      <link>/ai-ml-post/treesml/</link>
      <pubDate>Sun, 05 Jul 2020 01:35:10 -0400</pubDate>
      
      <guid>/ai-ml-post/treesml/</guid>
      <description>Trees are well-known as a non-linear data structure. They don’t store data in a linear way. They organize data hierarchically.
A tree is a collection of entities called nodes. Nodes are connected by edges. Each node contains a value or data, and it may or may not have a child node.
The Image at the beginning of the article (Source) explains the terminologies of a Tree.
Decision Trees Decision trees represent rules, which can be understood by humans and used in knowledge system such as database</description>
    </item>
    
    <item>
      <title>Bagging &amp; Boosting in Machine Learning World</title>
      <link>/ai-ml-post/baggingboosting/</link>
      <pubDate>Sat, 04 Jul 2020 10:52:27 -0400</pubDate>
      
      <guid>/ai-ml-post/baggingboosting/</guid>
      <description>In my last tech blog, I discussed on Decision trees and Random Forrest. So I thought of articulating on Gradient Boosting model and XgBoost. But before these algorithms , its important to understand 2 basic concepts :
 Bagging (Bootstrap Aggregation) Boosting  Bagging (Bootstrap Aggregation) Bootstrapping is a process of creating random samples with replacement for estimating sample statistics. With replacement means , the sample might have duplicated values from the original set.</description>
    </item>
    
    <item>
      <title></title>
      <link>/credits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/credits/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About the Blog</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I consider myself as Life long - &amp;ldquo;Vidyārthī&amp;rdquo; which is a Sanskrit word (means &amp;ldquo;Student&amp;rdquo;). This website is my journal on sharing technology knowledge with everyone and also learn during my tech journey.
Areas of Interests  Architechture &amp;amp; System Design Big Data , Datalake , DeltaLake Cloud and distributed computing Artificial &amp;amp; Machine learning Algorithms &amp;amp; Code complexities  Have questions or suggestions? Feel free to email - dev.techvidyarthi@gmail.com</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description> Contact : dev.techvidyarthi@gmail.com | debaditya.chakravorty@gmail.com  </description>
    </item>
    
    <item>
      <title>Hobby Projects</title>
      <link>/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description>Social Distancing Application In this fun project (Social distance Detection) , I am using YOLO (You only look once) + weights and COCO (Common Objects in Context) dataset for identifying person in real-time video.
 Yolo V3 COCO labels Distance : Euclidean (between boxes)  We can create the same concept in our workplace and maintain social distancing.
Inspiration This home project is inspired from Sir Andrew Ng&amp;rsquo;s startup More details are here</description>
    </item>
    
    <item>
      <title>Hobby Projects</title>
      <link>/showcase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/showcase/</guid>
      <description>Social Distancing Application In this fun project (Social distance Detection) , I am using YOLO (You only look once) + weights and COCO (Common Objects in Context) dataset for identifying person in real-time video.
 Yolo V3 COCO labels Distance : Euclidean (between boxes)  We can create the same concept in our workplace and maintain social distancing.
Inspiration This home project is inspired from Sir Andrew Ng&amp;rsquo;s startup More details are here</description>
    </item>
    
  </channel>
</rss>