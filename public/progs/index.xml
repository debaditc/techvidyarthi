<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Progs on Debaditya&#39;s Tech Journal</title>
    <link>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/</link>
    <description>Recent content in Progs on Debaditya&#39;s Tech Journal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 08 Aug 2020 20:57:34 -0400</lastBuildDate>
    
	<atom:link href="http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Basic Spark Commands</title>
      <link>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparkcommands/</link>
      <pubDate>Sat, 08 Aug 2020 20:57:34 -0400</pubDate>
      
      <guid>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparkcommands/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About Spark Memory and Optimizer </title>
      <link>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparkmemory/</link>
      <pubDate>Sat, 08 Aug 2020 20:28:12 -0400</pubDate>
      
      <guid>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparkmemory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spark Learnings</title>
      <link>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparklearn/</link>
      <pubDate>Sat, 08 Aug 2020 17:14:45 -0400</pubDate>
      
      <guid>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/sparklearn/</guid>
      <description>Install Spark For Windows : Please follow this site
Basics of Spark Flow Run Spark application -&amp;gt; Driver program starts -&amp;gt; Main function starts -&amp;gt; SparkContext gets initiated -&amp;gt; Driver program runs the operations inside the executors on worker nodes. SparkContext uses Py4J to launch a JVM and creates a JavaSparkContext. By default, PySpark has SparkContext available as ‘sc’, so creating a new SparkContext won&amp;rsquo;t work.
Execution of Spark Job   Image Credits to Data Flair</description>
    </item>
    
    <item>
      <title>Time &amp; Space Complexity</title>
      <link>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/tscomplexity/</link>
      <pubDate>Fri, 24 Jul 2020 00:03:26 -0400</pubDate>
      
      <guid>http://techvidyarthi.com.s3-website.us-east-1.amazonaws.com/progs/tscomplexity/</guid>
      <description>Time Complexity Big-O , Big-Omega , Big-Theta
 Big-O is the upper asymptotic bound for an algorithm . Worst-case scenarios Big-Omega is the lower bound asymptotic bound of an algorithm. Bast-case sceanrio Big-Theta is in between lower and upper asymptotic bound (tight bound) of an algorithm. Average or expected case scenario  Space Complexity Amount of memory or space required by an algorithm
In recursive calls counts,the code would take 0 (n) time and O( n) space.</description>
    </item>
    
  </channel>
</rss>